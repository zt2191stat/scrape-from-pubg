{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.75'}\n",
    "COOKIES = {'__cfduid': 'd44db92eab1474bde64206da8c5e0f5b11507046474',\n",
    "           'cf_clearance': '187c74875d4cb11dd9c985baae1cb43c272bf631-1507209348-1800',\n",
    "           'language': 'en-US',\n",
    "           'cdmu': '1507082693368',\n",
    "           'cdmblk2': '0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0; cdmblk=0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0',\n",
    "           'cdmtlk': '0:0:0:0:0:0:0:0:0:0:0:0:0:0',\n",
    "           'cdmgeo': 'us',\n",
    "           'cdmbaserate': '2.1',\n",
    "           'cdmbaseraterow': '1.1',\n",
    "           'cdmint': '0'}\n",
    "\n",
    "\n",
    "def get_soup(url, headers=HEADERS, cookies=COOKIES):\n",
    "    req = requests.get(url, headers=headers, cookies=cookies)\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    return soup\n",
    "\n",
    "# get player info from the page\n",
    "# for duo or squad data, change the string at line 47\n",
    "def get_player(soup):\n",
    "    url = 'https://pubg.me'\n",
    "    players = (soup.body.div.next_sibling.div.div.next_sibling.div.div.next_sibling\n",
    "              .table.tbody.find_all('tr'))\n",
    "    link_pool = []\n",
    "    for player in players:\n",
    "        link = url + player.find_all(class_=\"sidebar-user-link\")[0].attrs['href'] + '/solo'\n",
    "        link_pool.append(link)\n",
    "    return link_pool\n",
    "\n",
    "# get player data from each page\n",
    "def get_data(url):\n",
    "    soup = get_soup(url)\n",
    "    data = soup.find_all('div', class_='card mb-3')\n",
    "    ID = soup.find_all('div', class_='card-header')[0].contents[0].contents[1].contents[0].string\n",
    "    data_list = []\n",
    "    for i in data:\n",
    "        data_list += i.find_all('div', class_='col-md-4')\n",
    "    value_list = []\n",
    "    label_list = []\n",
    "    label_list.append(\"ID\")\n",
    "    value_list.append(ID)\n",
    "    for i in data_list:\n",
    "        for j in i.contents:\n",
    "            value_list.append(j.contents[0].string)\n",
    "            label_list.append(j.contents[-1].string)\n",
    "    return [label_list, value_list]\n",
    "\n",
    "# concatenate all the data\n",
    "def get_all(link_pool):\n",
    "    i=0\n",
    "    while(get_data(link_pool[i])[0] == ['ID']):\n",
    "        i = i+1\n",
    "    data_list = np.array(get_data(link_pool[i])[0])\n",
    "    for link in link_pool:\n",
    "        user = get_data(link)[1]\n",
    "        if len(user) == 1:                          \n",
    "            data_list = np.vstack([data_list, user+[\"NAN\"]*37])\n",
    "        else:\n",
    "            data_list = np.vstack([data_list, user])\n",
    "    return data_list\n",
    "\n",
    "#output the data \n",
    "def out_csv(data, place):\n",
    "    name = 'pubg_%s.csv' % place\n",
    "    with open(name, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    data_as = get_all(get_player(get_soup('https://pubg.me/players/rating/?season=2017-pre5&region=as&match=solo')))\n",
    "    out_csv(data_as, 'as')\n",
    "    \n",
    "    data_eu = get_all(get_player(get_soup('https://pubg.me/players/rating/?season=2017-pre5&region=eu&match=solo')))\n",
    "    out_csv(data_eu, 'eu')\n",
    "\n",
    "    data_na = get_all(get_player(get_soup('https://pubg.me/players/rating/?season=2017-pre5&region=na&match=solo')))\n",
    "    out_csv(data_na, 'na')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_player(name):\n",
    "    url = 'https://pubg.me/player/'\n",
    "    link_pool = []\n",
    "    for player in name:\n",
    "        link = url + player + '/duo'\n",
    "        link_pool.append(link)\n",
    "    return link_pool\n",
    "\n",
    "# concatenate all the data\n",
    "def get_all(link_pool):\n",
    "    i=0\n",
    "    while(get_data(link_pool[i])[0] == ['ID']):\n",
    "        i = i+1\n",
    "    data_list = np.array(get_data(link_pool[i])[0])\n",
    "    for link in link_pool:\n",
    "        user = get_data(link)[1]\n",
    "        if len(user) == 1:                          \n",
    "            data_list = np.vstack([data_list, user+[\"NAN\"]*37])\n",
    "        else:\n",
    "            data_list = np.vstack([data_list, user])\n",
    "    return data_list\n",
    "\n",
    "\n",
    "# get player data from each page\n",
    "def get_data(url):\n",
    "    soup = get_soup(url)\n",
    "    data = soup.find_all('div', class_='card mb-3')\n",
    "    ID = url.split(\"/\")[4]\n",
    "    if data == []:\n",
    "        return [[\"ID\"] + [\"NAN\"]*37 , [ID] + [\"NAN\"]*37]\n",
    "    else:\n",
    "        data_list = []\n",
    "        for i in data:\n",
    "            data_list += i.find_all('div', class_='col-md-4')\n",
    "        value_list = []\n",
    "        label_list = []\n",
    "        label_list.append(\"ID\")\n",
    "        value_list.append(ID)\n",
    "        for i in data_list:\n",
    "            for j in i.contents:\n",
    "                value_list.append(j.contents[0].string)\n",
    "                label_list.append(j.contents[-1].string)\n",
    "        return [label_list, value_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cfscrape\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "\n",
    "HEADERS = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/61.0.3163.100 Safari/537.36'}\n",
    "COOKIES = {'__cfduid': 'd44db92eab1474bde64206da8c5e0f5b11507046474',\n",
    "           'cf_clearance': '187c74875d4cb11dd9c985baae1cb43c272bf631-1507209348-1800',\n",
    "           'language': 'en-US',\n",
    "           'cdmu': '1507082693368',\n",
    "           'cdmblk2': '0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0; cdmblk=0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0,0:0:0:0:0:0:0:0:0:0:0:0:0:0',\n",
    "           'cdmtlk': '0:0:0:0:0:0:0:0:0:0:0:0:0:0',\n",
    "           'cdmgeo': 'us',\n",
    "           'cdmbaserate': '2.1',\n",
    "           'cdmbaseraterow': '1.1',\n",
    "           'cdmint': '0'}\n",
    "\n",
    "\n",
    "def get_soup(url):\n",
    "    scraper = cfscrape.create_scraper()\n",
    "    req = scraper.get(url)\n",
    "    html = req.text\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"PUBG_Player_Statistics.csv\")\n",
    "name = data['player_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name = name.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = get_player(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def out_csv(pool):\n",
    "    data = get_all(pool)\n",
    "    name = 'pubg_data_duo.csv' \n",
    "    with open(name, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_csv(pool[:10000])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
